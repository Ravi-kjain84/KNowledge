Here’s a revised version of your text, with grammatical corrections, removal of duplicacies, and clearer academic language:

The implementation of finance on the cloud has facilitated seamless reporting for key financial operations, such as liquidity management and risk-weighted asset calculations. This system’s effectiveness is further enhanced by its ability to deliver timely results, not only on a monthly basis but daily as well.

The Finance Operations Transformation Center (FOTC) introduced a unified, well-governed, and controlled database (FCDP), designed to serve as a single source of truth for all purposes. While this development highlights the potential of structured data, challenges arise when data access is restricted to a limited number of stakeholders. The increasing manual workload faced by change delivery teams and the Run-the-Bank (RTB) teams has underscored the urgent need for a Transformation in Finance (TIF).

TIF embodies a commitment to the future of finance operations by empowering people, processes, regulators, and decision-makers through data-driven insights. This approach seeks to make these insights more accessible and user-friendly. Achieving this vision requires the development of Finance Data Services.

The goal of Finance Data Services is to establish a self-service platform that ensures the reliable distribution of data for financial purposes. This initiative is founded on principles of data refinement and efficient distribution.

This version removes unnecessary repetition, clarifies the ideas, and enhances readability while maintaining an academic tone. Let me know if you need further adjustments!


-----
def parse_formula(self, formula_logic, df, dependencies, data_type):
    # Mapping for operators
    ops = {
        '+': operator.add,
        '-': operator.sub,
        '*': operator.mul,
        '/': operator.truediv,
    }

    # Convert the formula logic to lowercase for case-insensitivity
    formula_logic_lower = formula_logic.lower()

    # Check if the formula contains an operator
    for op_symbol, op_func in ops.items():
        if op_symbol in formula_logic_lower:
            # Split the formula by the operator to get the operands
            operands = formula_logic.split(op_symbol)
            operand1 = operands[0].strip()
            operand2 = operands[1].strip()

            # Check if operand1 is a column in the dataframe or a literal value
            if operand1 in df.columns:
                operand1_value = df[operand1]
            else:
                try:
                    operand1_value = float(operand1)  # Convert literal to float or appropriate type
                except ValueError:
                    raise ValueError(f"Invalid value for operand1: {operand1}")

            # Check if operand2 is a column in the dataframe or a literal value
            if operand2 in df.columns:
                operand2_value = df[operand2]
            else:
                try:
                    operand2_value = float(operand2)  # Convert literal to float or appropriate type
                except ValueError:
                    raise ValueError(f"Invalid value for operand2: {operand2}")

            # Apply the operator function
            result = op_func(operand1_value, operand2_value)

            # Return the result, cast to the correct type if necessary
            if data_type == 'float':
                return result.astype(float)
            elif data_type == 'int':
                return result.astype(int)
            else:
                return result.astype(object)

    # Handle other cases like 'if-then-else' or 'astype' (as per your existing logic)
    # ... (existing logic for other cases)


----
import subprocess
import os
from tkinter import messagebox

def run_process1(self):
    if not python_file:
        messagebox.showerror("Error", "Please select a Python file for {PROCESS_1_NAME}.")
        return

    output_folder = filedialog.askdirectory(title="Select Output Folder for {PROCESS_1_NAME}")
    if not output_folder:
        messagebox.showerror("Error", f"Please select an output folder for {PROCESS_1_NAME}.")
        return

    try:
        # Convert paths to absolute paths
        python_file_abs = os.path.abspath(python_file)
        output_folder_abs = os.path.abspath(output_folder)
        filepath1_current_abs = os.path.abspath(self.filepath1_current)

        # Run the selected Python file with the absolute paths
        result = subprocess.run(
            [sys.executable, python_file_abs, filepath1_current_abs, output_folder_abs],
            capture_output=True,  # Capture the output
            text=True  # Return the output as a string instead of bytes
        )

        # Check for errors and display the output
        if result.returncode == 0:
            messagebox.showinfo("Success", f"{PROCESS_1_NAME} completed successfully. Output saved in {output_folder_abs}.")
            messagebox.showinfo("Output", f"Script Output:\n{result.stdout}")
        else:
            messagebox.showerror("Error", f"An error occurred during {PROCESS_1_NAME} execution.\nError:\n{result.stderr}")

    except Exception as e:
        messagebox.showerror("Error", f"An error occurred during {PROCESS_1_NAME} execution: {e}")



-----
import os
import pandas as pd

def run_for_each_folder(data_folder, output_folder):
    """
    Function to process data in the 'data_folder' and store output in 'output_folder'.
    Reads input and mapping files in .xlsx format, merges based on two columns, 
    and saves the final DataFrame to an .xlsx file.
    """

    # Define paths for input and mapping files
    input_file_path = os.path.join(data_folder, 'input', 'input01.xlsx')  # Assuming Excel format
    mapping_file_path = os.path.join(data_folder, 'mapping', 'mapping1.xlsx')  # Assuming Excel format
    output_file_path = os.path.join(output_folder, 'output01.xlsx')

    # Check if necessary folders and files exist
    if os.path.exists(input_file_path) and os.path.exists(mapping_file_path):
        print(f"Processing data in: {data_folder}")
        print(f"Storing results in: {output_folder}")

        # Read the input and mapping files into DataFrames (first sheet is read by default)
        input_df = pd.read_excel(input_file_path)
        mapping_df = pd.read_excel(mapping_file_path)

        # Merge the dataframes based on common columns (replace 'common_col1' and 'common_col2' with actual column names)
        merged_df = pd.merge(input_df, mapping_df, left_on=['common_col1', 'common_col2'], right_on=['common_col1', 'common_col2'])

        # Select the columns you want from the mapping file (replace 'mapping_col1' and 'mapping_col2' with actual column names)
        final_df = merged_df[['column_from_input1', 'column_from_input2', 'mapping_col1', 'mapping_col2']]

        # Save the final DataFrame to the output folder as an Excel file
        final_df.to_excel(output_file_path, index=False)
        print(f"Successfully processed data and saved output to {output_file_path}.")
    else:
        print("Either input or mapping file doesn't exist.")

# Example usage
data_folder = '/path/to/data_folder'  # Replace with actual path
output_folder = '/path/to/output_folder'  # Replace with actual path
run_for_each_folder(data_folder, output_folder)



-------------

def ensure_column_exists(df, column_name, default_value=0):
    if column_name not in df.columns:
        df[column_name] = default_value  # Add the missing column with the default value
    return df

def write_output(self):
    # Ensure the output folder exists
    try:
        app = xw.App(visible=False)
        workbook = app.books.open('output/Singapore/output.xlsx')
        
        # Ensure the missing column is in df_control_01 and final_upload_df
        missing_column = 'YourMissingColumnName'
        self.df_control_01 = ensure_column_exists(self.df_control_01, missing_column)
        self.final_upload_df = ensure_column_exists(self.final_upload_df, missing_column)
        
        # Clear the contents of the 'df_control_01' sheet
        sheet1 = workbook.sheets['df_control_01']
        sheet1.clear()
        
        # Write data to 'df_control_01'
        sheet1.range('A1').value = self.df_control_01.columns.tolist()
        sheet1.range('A2').value = self.df_control_01.values.tolist()
        
        # Clear the contents of the 'final_upload_df' sheet
        sheet2 = workbook.sheets['final_upload_df']
        sheet2.clear()
        
        # Write data to 'final_upload_df'
        sheet2.range('A1').value = self.final_upload_df.columns.tolist()
        sheet2.range('A2').value = self.final_upload_df.values.tolist()
        
        workbook.save()
        workbook.close()

    finally:
        app.kill()

----


import pandas as pd
import numpy as np
from openpyxl import Workbook
from openpyxl.styles import PatternFill

# Assuming df1 and df2 are your two DataFrames
# Concatenate all columns into one column for both DataFrames
df1['combined'] = df1.astype(str).agg(' | '.join, axis=1)
df2['combined'] = df2.astype(str).agg(' | '.join, axis=1)

# Compare the combined columns row by row
df1['match'] = df1['combined'] == df2['combined']

# Add a new column to indicate rows that do not match
df1['comparison_result'] = np.where(df1['match'], 'Matched', 'Not Matched')

# Drop the combined and match columns before export
df1 = df1.drop(columns=['combined', 'match'])

# Function to highlight cells in red where there is a mismatch
def highlight_unmatched(s, df2_row):
    return ['background-color: red' if s.iloc[i] != df2_row.iloc[i] else '' for i in range(len(s))]

# Apply the highlighting function to each row
highlighted_df = df1.style.apply(lambda s: highlight_unmatched(s, df2.loc[s.name]), axis=1)

# Write the output to an Excel file
output_path = 'comparison_output.xlsx'
with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
    highlighted_df.to_excel(writer, sheet_name='Comparison', index=False)

# Load the workbook and adjust the formatting for the new column
wb = Workbook()
ws = wb.active

# Open the existing Excel file to modify it
from openpyxl import load_workbook
wb = load_workbook(output_path)
ws = wb.active

# Save the modified workbook
wb.save(output_path)


-------

import pandas as pd

# Sample data for DataFrame 1 (df1) and DataFrame 2 (df2)
# Assuming you have already loaded df1 and df2

# df1 represents the consolidated data
# df2 represents the granular data with Entity column populated

# Merging df1 with df2 on common columns (excluding 'Entity' and 'Amount')
merged_df = df1.merge(df2, on=[col for col in df1.columns if col not in ['Entity', 'Amount']], how='left', suffixes=('', '_df2'))

# Calculating the residual (difference) between the Amount in df1 and the sum of the Amount in df2
merged_df['Residual'] = merged_df['Amount'] - merged_df['Amount_df2'].fillna(0)

# Updating df1's Entity and Amount columns based on df2
merged_df['Entity'] = merged_df['Entity_df2'].fillna('NA')
merged_df['Amount'] = merged_df['Amount_df2'].fillna(merged_df['Residual'])

# Dropping temporary columns used for merging
merged_df.drop(columns=['Entity_df2', 'Amount_df2', 'Residual'], inplace=True)

# The resulting DataFrame is now stored in merged_df
# You can save this DataFrame back to df1 if needed
df1_updated = merged_df

# Display the updated DataFrame
print(df1_updated)





---------

import pandas as pd

# Assuming your DataFrame is named df

# Convert all columns to string, except for the 'amount' column
df = df.applymap(lambda x: str(x) if isinstance(x, (int, float, bool, object)) else x)

# Ensure that the 'amount' column remains unchanged
df['amount'] = df['amount'].astype(float)

# Display the DataFrame to verify the changes
print(df.dtypes)

----



import pandas as pd

# Assuming df1 is for July and df2 is for August
# Example dataframes
# df1 = pd.read_csv('path_to_july_data.csv')
# df2 = pd.read_csv('path_to_august_data.csv')

# Sample data creation (remove this part if you are reading from CSV)
data_july = {
    'date': ['2023-07-31']*5,
    'col1': ['A', 'B', 'A', 'C', 'D'],
    'col2': ['X', 'Y', 'X', 'Z', 'Y'],
    'amount': [100, 150, 200, 250, 300]
}

data_august = {
    'date': ['2023-08-31']*5,
    'col1': ['A', 'B', 'E', 'C', 'F'],
    'col2': ['X', 'Y', 'W', 'Z', 'V'],
    'amount': [110, 160, 210, 260, 310]
}

df1 = pd.DataFrame(data_july)
df2 = pd.DataFrame(data_august)

# Convert all columns to string type
df1 = df1.astype(str)
df2 = df2.astype(str)

# List of columns excluding 'amount'
columns_to_check = [col for col in df1.columns if col != 'amount']

# Create an empty result dataframe
result_df = pd.DataFrame(columns=['Column', 'Current Distinct Count', 'Previous Distinct Count'])

# Calculate distinct counts for each column
for col in columns_to_check:
    current_count = df2[col].nunique()
    previous_count = df1[col].nunique()
    result_df = result_df.append({'Column': col, 'Current Distinct Count': current_count, 'Previous Distinct Count': previous_count}, ignore_index=True)

# Display the result
print(result_df)





-------


import pandas as pd

# Sample data creation
data_july = {
    'date': ['2023-07-31']*5,
    'country': ['US', 'US', 'IN', 'IN', 'UK'],
    'account': ['A1', 'A2', 'B1', 'B2', 'C1'],
    'amount': [100, 150, 200, 250, 300],
    'other1': ['x1', 'x2', 'x3', 'x4', 'x5'],
    'other2': ['y1', 'y2', 'y3', 'y4', 'y5']
}

data_august = {
    'date': ['2023-08-31']*5,
    'country': ['US', 'US', 'IN', 'IN', 'UK'],
    'account': ['A1', 'A2', 'B1', 'B2', 'C1'],
    'amount': [110, 160, 210, 260, 310],
    'other1': ['x6', 'x7', 'x8', 'x9', 'x10'],
    'other2': ['y6', 'y7', 'y8', 'y9', 'y10']
}

df1 = pd.DataFrame(data_july)
df2 = pd.DataFrame(data_august)

# Convert all columns to string type
df1 = df1.astype(str)
df2 = df2.astype(str)

# Convert 'amount' column back to float for aggregation purposes
df1['amount'] = df1['amount'].astype(float)
df2['amount'] = df2['amount'].astype(float)

# Summarize amount by country for both dataframes
sum_country_july = df1.groupby('country')['amount'].sum().reset_index()
sum_country_august = df2.groupby('country')['amount'].sum().reset_index()

# Merge the summarized dataframes on 'country'
result_country = pd.merge(sum_country_july, sum_country_august, on='country', suffixes=('_previous', '_current'))

# Summarize amount by country and account for both dataframes
sum_country_account_july = df1.groupby(['country', 'account'])['amount'].sum().reset_index()
sum_country_account_august = df2.groupby(['country', 'account'])['amount'].sum().reset_index()

# Merge the summarized dataframes on 'country' and 'account'
result_country_account = pd.merge(sum_country_account_july, sum_country_account_august, on=['country', 'account'], suffixes=('_previous', '_current'))

# Summarize amount by account for both dataframes
sum_account_july = df1.groupby('account')['amount'].sum().reset_index()
sum_account_august = df2.groupby('account')['amount'].sum().reset_index()

# Merge the summarized dataframes on 'account'
result_account = pd.merge(sum_account_july, sum_account_august, on='account', suffixes=('_previous', '_current'))

# Display results
print("Summarized amount by country:")
print(result_country)
print("\nSummarized amount by country and account:")
print(result_country_account)
print("\nSummarized amount by account:")
print(result_account)




---------

import pandas as pd

def process_unmatched_values(df):
    unmatched_values_list = []
    
    # Get the unique country names
    unique_countries = df['Country'].unique()
    
    for country in unique_countries:
        # Filter the DataFrame for the current country
        country_df = df[df['Country'] == country]
        
        # Add your existing logic here to create unmatched values
        # This part is based on your original code
        
        # Assuming mapping_df and keys are defined outside this function
        for map_ in mapping_df.keys():
            map_keys = keys['main']
            
            merged_df = country_df.merge(mapping_df[map_], how='left', left_on=map_keys, right_on=map_keys, indicator=True)
            
            # Identify the rows in country_df that don't have matches in the mapping DataFrame
            unmatched = merged_df[merged_df['_merge'] == 'left_only'][map_keys]
            for value in unmatched.itertuples(index=False, name=None):
                unmatched_values_list.append({
                    'Dataframe': map_,
                    'Key Column': ', '.join(map(str, map_keys)),
                    'Missing Value': ', '.join(map(str, value)),
                    'Country': country
                })
    
    # Create a DataFrame from the unmatched values list
    unmatched_values_df = pd.DataFrame(unmatched_values_list, columns=['Dataframe', 'Key Column', 'Missing Value', 'Country'])
    
    # Remove duplicate rows based on 'Dataframe', 'Key Column', and 'Missing Value', but combine 'Country' values
    unmatched_values_df = unmatched_values_df.groupby(['Dataframe', 'Key Column', 'Missing Value']).agg({
        'Country': lambda x: ', '.join(sorted(set(x)))
    }).reset_index()
    
    return unmatched_values_df

# Example usage:
# df is your input DataFrame
unmatched_values_df = process_unmatched_values(df)

# If you need to run this function multiple times and append the results, you can do:
final_unmatched_values_df = pd.DataFrame()
for df in list_of_dataframes:  # Assuming you have a list of DataFrames to process
    result_df = process_unmatched_values(df)
    final_unmatched_values_df = pd.concat([final_unmatched_values_df, result_df], ignore_index=True)

# Now final_unmatched_values_df contains the combined results







---------

def missing_transaction_mapping(self):

    # Create a list to store the unmatched values
    unmatched_values_list = []

    # Get the unique country value from the final_df_engine
    unique_country = self.final_df_engine['country'].unique()
    if len(unique_country) == 1:
        country_name = unique_country[0]
    else:
        # Handle the case where there are multiple unique countries, if needed
        country_name = 'Multiple'

    # Merge main_df with each mapping DataFrame and track unmatched values
    for name, mapping_df, keys in self.missing_mapping:
        main_keys = keys['main']
        map_keys = keys['map']

        # Ensure the country column is included in the merged DataFrame
        merged_df = self.final_df_engine.merge(mapping_df, how='left', left_on=main_keys, right_on=map_keys, indicator=True)

        # Identify the rows in main_df that don't have matching rows in the mapping DataFrame
        unmatched = merged_df[merged_df['_merge'] == 'left_only'][main_keys]
        
        for value in unmatched.itertuples(index=False, name=None):
            unmatched_values_list.append((name, country_name, *value, ','.join(map(str, value))))

    # Create a DataFrame from the unmatched values list
    self.unmatched_values_df = pd.DataFrame(unmatched_values_list, columns=['DataFrame', 'Country', 'Key Column', 'Missing Value'])
    # self.unmatched_values_df['Missing Value'] = self.unmatched_values_df['Missing Value'].replace(['', None])
    # self.unmatched_values_df = self.unmatched_values_df[self.unmatched_values_df['Missing Value'].str.contains('NA', na=False)]
    # self.unmatched_values_df['Missing Value'] = self.unmatched_values_df['Missing Value'] != ''
    # self.unmatched_values_df['Missing Value'] = self.unmatched_values_df['Missing Value'] != None
    # self.unmatched_values_df = self.unmatched_values_df[self.unmatched_values_df['Missing Value'].str.contains('ICP None', na=False)]
    # self.unmatched_values_df = self.unmatched_values_df.drop_duplicates()

-------



import pandas as pd
import win32com.client
import psutil

# Define the path to your PowerPoint file
ppt_file_path = 'path/to/your/presentation.pptx'

# Define the dictionary with chart names and their corresponding DataFrames
chart_data_dict = {
    'Chart1': pd.DataFrame({
        'Category': ['A', 'B', 'C', 'D'],
        'Value': [10, 20, 30, 40]
    }),
    'Chart2': pd.DataFrame({
        'Category': ['W', 'X', 'Y', 'Z'],
        'Value': [15, 25, 35, 45]
    })
    # Add more DataFrames as needed
}

def get_excel_processes():
    """Returns a list of PIDs for all running Excel processes."""
    return [p.pid for p in psutil.process_iter(['name']) if p.info['name'] == 'EXCEL.EXE']

def update_chart_data(ppt_file_path, chart_data_dict):
    # Get the list of Excel processes before running the script
    pre_existing_excel_pids = get_excel_processes()

    # Open the PowerPoint file using win32com
    Application = win32com.client.Dispatch("PowerPoint.Application")
    Presentation = Application.Presentations.Open(ppt_file_path, ReadOnly=False)

    # Iterate through slides and shapes to find the charts
    for slide in Presentation.Slides:
        for shape in slide.Shapes:
            if shape.HasChart:
                chart = shape.Chart
                chart_name = shape.Name

                # Check if the chart's name corresponds to a DataFrame in the dictionary
                if chart_name in chart_data_dict:
                    df = chart_data_dict[chart_name]

                    # Update chart data
                    chart.ChartData.Activate()
                    workbook = chart.ChartData.Workbook
                    worksheet = workbook.Worksheets(1)

                    # Clear existing data
                    worksheet.Cells.Clear()

                    # Write new data
                    worksheet.Cells(1, 1).Value = "Category"
                    worksheet.Cells(1, 2).Value = "Value"
                    for i, (index, row) in enumerate(df.iterrows(), start=2):
                        worksheet.Cells(i, 1).Value = row['Category']
                        worksheet.Cells(i, 2).Value = row['Value']

                    # Refresh the chart
                    chart.Refresh()

    # Save and close the presentation
    Presentation.Save()
    Presentation.Close()
    Application.Quit()

    # Get the list of Excel processes after running the script
    post_existing_excel_pids = get_excel_processes()

    # Find new Excel processes that were started by the script
    new_excel_pids = set(post_existing_excel_pids) - set(pre_existing_excel_pids)

    # Terminate new Excel processes
    for pid in new_excel_pids:
        p = psutil.Process(pid)
        p.terminate()
        p.wait()

update_chart_data(ppt_file_path, chart_data_dict)

print("Charts updated in PowerPoint presentation and new Excel processes closed.")










---------------------------

import pandas as pd
import win32com.client
import psutil

# Define the path to your PowerPoint file
ppt_file_path = 'path/to/your/presentation.pptx'

# Define the data frames corresponding to each chart
data_frames = {
    'Chart1': pd.DataFrame({
        'Category': ['A', 'B', 'C', 'D'],
        'Value': [10, 20, 30, 40]
    }),
    'Chart2': pd.DataFrame({
        'Category': ['W', 'X', 'Y', 'Z'],
        'Value': [15, 25, 35, 45]
    })
    # Add more DataFrames as needed
}

def get_excel_processes():
    """Returns a list of PIDs for all running Excel processes."""
    return [p.pid for p in psutil.process_iter(['name']) if p.info['name'] == 'EXCEL.EXE']

def update_chart_data(ppt_file_path, data_frames):
    # Get the list of Excel processes before running the script
    pre_existing_excel_pids = get_excel_processes()

    # Open the PowerPoint file using win32com
    Application = win32com.client.Dispatch("PowerPoint.Application")
    Presentation = Application.Presentations.Open(ppt_file_path, ReadOnly=False)

    # Iterate through slides and shapes to find the charts
    for slide in Presentation.Slides:
        for shape in slide.Shapes:
            if shape.HasChart:
                chart = shape.Chart
                chart_name = shape.Name

                # Check if the chart's name corresponds to a DataFrame in the data_frames dictionary
                if chart_name in data_frames:
                    df = data_frames[chart_name]

                    # Update chart data
                    chart.ChartData.Activate()
                    workbook = chart.ChartData.Workbook
                    worksheet = workbook.Worksheets(1)

                    # Clear existing data
                    worksheet.Cells.Clear()

                    # Write new data
                    worksheet.Cells(1, 1).Value = "Category"
                    worksheet.Cells(1, 2).Value = "Value"
                    for i, (index, row) in enumerate(df.iterrows(), start=2):
                        worksheet.Cells(i, 1).Value = row['Category']
                        worksheet.Cells(i, 2).Value = row['Value']

                    # Refresh the chart
                    chart.Refresh()

    # Save and close the presentation
    Presentation.Save()
    Presentation.Close()
    Application.Quit()

    # Get the list of Excel processes after running the script
    post_existing_excel_pids = get_excel_processes()

    # Find new Excel processes that were started by the script
    new_excel_pids = set(post_existing_excel_pids) - set(pre_existing_excel_pids)

    # Terminate new Excel processes
    for pid in new_excel_pids:
        p = psutil.Process(pid)
        p.terminate()
        p.wait()

update_chart_data(ppt_file_path, data_frames)

print("Charts updated in PowerPoint presentation and new Excel processes closed.")








-------------------------------------


from pptx import Presentation
from pptx.util import Pt
from pptx.dml.color import RGBColor
from pptx.enum.text import PP_ALIGN

# Load the existing presentation
prs = Presentation('your_presentation.pptx')

# Access the slide containing the table
slide = prs.slides[0]  # Adjust index to the slide with your table

# Access the table (assuming it's the first table on the slide)
table = slide.shapes[0].table

# Specify the column index you want to align (0-based index)
column_index = 0  # Change to the desired column index

# Iterate through the rows and access the cell in the specified column
for row in table.rows:
    cell = row.cells[column_index]
    
    # Align text to the center
    for paragraph in cell.text_frame.paragraphs:
        paragraph.alignment = PP_ALIGN.CENTER  # Center alignment

# Save the presentation with the updated table
prs.save('updated_presentation.pptx')



----///------///-----

from pptx.enum.text import PP_ALIGN

for cell in table.columns[0].cells:
    cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER  # Center alignment

-------



import pandas as pd
from pptx import Presentation
from pptx.util import Inches
import win32com.client

# Define the path to your PowerPoint file and the chart data
ppt_file_path = 'path/to/your/presentation.pptx'
new_data = {
    'Category': ['A', 'B', 'C', 'D'],
    'Value': [10, 20, 30, 40]
}
df = pd.DataFrame(new_data)

def update_chart_data(ppt_file_path, df):
    # Open the PowerPoint file using win32com
    Application = win32com.client.Dispatch("PowerPoint.Application")
    Presentation = Application.Presentations.Open(ppt_file_path, ReadOnly=False)

    # Iterate through slides and shapes to find the chart
    for slide in Presentation.Slides:
        for shape in slide.Shapes:
            if shape.HasChart:
                chart = shape.Chart
                # Update chart data
                chart.ChartData.Activate()
                workbook = chart.ChartData.Workbook
                worksheet = workbook.Worksheets(1)

                # Clear existing data
                worksheet.Cells.Clear()

                # Write new data
                worksheet.Cells(1, 1).Value = "Category"
                worksheet.Cells(1, 2).Value = "Value"
                for i, (index, row) in enumerate(df.iterrows(), start=2):
                    worksheet.Cells(i, 1).Value = row['Category']
                    worksheet.Cells(i, 2).Value = row['Value']

                # Refresh the chart
                chart.Refresh()
    
    # Save and close the presentation
    Presentation.Save()
    Presentation.Close()
    Application.Quit()

update_chart_data(ppt_file_path, df)

print("Chart data updated in PowerPoint presentation.")






------------------------------

run.font.name = 'Arial'

from pptx.dml.color import RGBColor

for row in table.rows:
    for cell in row.cells:
        cell.fill.solid()
        cell.fill.fore_color.rgb = RGBColor(255, 255, 0)  # Yellow background


run.font.underline = True


from pptx.dml.color import RGBColor

for row in table.rows:
    for cell in row.cells:
        cell.fill.solid()
        cell.fill.fore_color.rgb = RGBColor(255, 255, 0)  # Yellow background
-----

from pptx import Presentation
from pptx.util import Pt
from pptx.dml.color import RGBColor

# Load the existing presentation
prs = Presentation('your_presentation.pptx')

# Access the slide containing the table
slide = prs.slides[0]  # Adjust index to the slide with your table

# Access the table (assuming it's the first table on the slide)
table = slide.shapes[0].table

# Modify font properties for each cell
for row in table.rows:
    for cell in row.cells:
        for paragraph in cell.text_frame.paragraphs:
            for run in paragraph.runs:
                run.font.size = Pt(12)  # Set font size
                run.font.bold = True  # Make text bold
                run.font.italic = False  # Make text italic
                run.font.color.rgb = RGBColor(0, 0, 255)  # Set font color (blue)

# Save the presentation with the updated table
prs.save('updated_presentation.pptx')









-/:-::-/:::///////

import pandas as pd
from pptx import Presentation
from pptx.util import Inches
import win32com.client

# Define the path to your PowerPoint file and the chart data
ppt_file_path = 'path/to/your/presentation.pptx'
new_data = {
    'Category': ['A', 'B', 'C', 'D'],
    'Value': [10, 20, 30, 40]
}
df = pd.DataFrame(new_data)

def update_chart_data(ppt_file_path, df):
    # Open the PowerPoint file using win32com
    Application = win32com.client.Dispatch("PowerPoint.Application")
    Presentation = Application.Presentations.Open(ppt_file_path, ReadOnly=False)

    # Iterate through slides and shapes to find the chart
    for slide in Presentation.Slides:
        for shape in slide.Shapes:
            if shape.HasChart:
                chart = shape.Chart
                # Update chart data
                chart.ChartData.Activate()
                workbook = chart.ChartData.Workbook
                worksheet = workbook.Worksheets(1)

                # Clear existing data
                worksheet.Cells.Clear()

                # Write new data
                worksheet.Cells(1, 1).Value = "Category"
                worksheet.Cells(1, 2).Value = "Value"
                for i, (index, row) in enumerate(df.iterrows(), start=2):
                    worksheet.Cells(i, 1).Value = row['Category']
                    worksheet.Cells(i, 2).Value = row['Value']

                # Refresh the chart
                chart.Refresh()
    
    # Save and close the presentation
    Presentation.Save()
    Presentation.Close()
    Application.Quit()

update_chart_data(ppt_file_path, df)

print("Chart data updated in PowerPoint presentation.")





-------

import pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import PatternFill
from openpyxl.utils.dataframe import dataframe_to_rows

def write_df_to_excel(df, file_path, sheet_name='Sheet1'):
    """
    Writes a Pandas DataFrame to an Excel file.

    Parameters:
        df (pd.DataFrame): The DataFrame to write.
        file_path (str): The path to the Excel file.
        sheet_name (str): The name of the sheet to write the DataFrame to.

    Returns:
        None
    """
    df.to_excel(file_path, index=False, sheet_name=sheet_name)

def adjust_column_widths(ws):
    """
    Adjusts the column widths of the worksheet based on the length of the longest value in each column.

    Parameters:
        ws (Worksheet): The worksheet to adjust column widths for.

    Returns:
        None
    """
    for col in ws.columns:
        max_length = 0
        column = col[0].column_letter  # Get the column name
        for cell in col:
            try:
                if len(str(cell.value)) > max_length:
                    max_length = len(cell.value)
            except:
                pass
        adjusted_width = (max_length + 2)
        ws.column_dimensions[column].width = adjusted_width

def apply_conditional_formatting(ws):
    """
    Applies conditional formatting to the worksheet.

    Parameters:
        ws (Worksheet): The worksheet to apply conditional formatting to.

    Returns:
        None
    """
    # Example: Apply a yellow fill to column 'A' if value is greater than 2
    yellow_fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')

    for cell in ws['A']:
        if cell.row == 1:  # Skip the header row
            continue
        if cell.value > 2:
            cell.fill = yellow_fill

def process_all_sheets(file_path):
    """
    Processes all worksheets in the given Excel file, adjusting column widths and applying conditional formatting.

    Parameters:
        file_path (str): The path to the Excel file.

    Returns:
        None
    """
    # Load the workbook
    wb = load_workbook(file_path)
    
    # Iterate through all worksheets in the workbook
    for ws in wb.worksheets:
        # Adjust column widths
        adjust_column_widths(ws)
        # Apply conditional formatting
        apply_conditional_formatting(ws)
    
    # Save the workbook
    wb.save(file_path)

def main():
    # Create a sample DataFrame
    data = {
        'A': [1, 2, 3, 4],
        'B': [5, 6, 7, 8],
        'C': [9, 10, 11, 12]
    }
    df = pd.DataFrame(data)

    # Define the file path
    file_path = 'output.xlsx'

    # Write the DataFrame to an Excel file
    write_df_to_excel(df, file_path)

    # Process all sheets in the workbook
    process_all_sheets(file_path)

    print("DataFrame written to Excel with adjusted column widths and conditional formatting applied to all worksheets.")

if __name__ == "__main__":
    main()





-----

from pptx import Presentation
from pptx.util import Inches, Pt
import pandas as pd
import matplotlib.pyplot as plt
import io
import comtypes.client

def update_presentation(pptx_path, output_pptx_path, output_pdf_path, images_to_replace, tables_to_replace, text_boxes_to_replace):
    # Load the existing presentation
    prs = Presentation(pptx_path)

    # Function to create a chart from a dataframe and return as an image stream
    def create_chart_image(dataframe):
        fig, ax = plt.subplots()
        ax.bar(dataframe['Category'], dataframe['Values'])
        ax.set_title("Sample Data Chart")

        # Save the plot to a BytesIO object
        img_stream = io.BytesIO()
        plt.savefig(img_stream, format='png')
        img_stream.seek(0)

        # Close the plot to free memory
        plt.close(fig)
        
        return img_stream

    # Iterate over slides and shapes to find and replace images, tables, and text boxes by their names
    for slide in prs.slides:
        for shape in slide.shapes:
            # Replace images
            if shape.shape_type == 13:  # 13 corresponds to picture shapes
                for image_info in images_to_replace:
                    if shape.name == image_info['name']:
                        # Get the position and size of the old image
                        left = shape.left
                        top = shape.top
                        width = shape.width
                        height = shape.height

                        # Remove the old picture
                        slide.shapes._spTree.remove(shape._element)

                        # Create the new chart image
                        chart_image_stream = create_chart_image(image_info['dataframe'])

                        # Add the new chart image with the same name
                        new_image = slide.shapes.add_picture(chart_image_stream, left, top, width, height)
                        new_image.name = image_info['name']

                        # Add a text box for the description
                        text_left = left
                        text_top = top + height + Inches(0.2)
                        text_width = width
                        text_height = Inches(1)

                        text_box = slide.shapes.add_textbox(text_left, text_top, text_width, text_height)
                        text_frame = text_box.text_frame
                        p = text_frame.add_paragraph()
                        p.text = image_info['description']
                        p.font.size = Pt(14)

            # Replace tables
            elif shape.shape_type == 19:  # 19 corresponds to table shapes
                for table_info in tables_to_replace:
                    if shape.name == table_info['name']:
                        table = shape.table
                        dataframe = table_info['dataframe']

                        # Clear the existing table contents
                        for row in table.rows:
                            for cell in row.cells:
                                cell.text = ''

                        # Fill the table with new data
                        for i, row in dataframe.iterrows():
                            for j, value in enumerate(row):
                                table.cell(i+1, j).text = str(value)  # +1 to skip header row

                        # Update the header row
                        for j, column in enumerate(dataframe.columns):
                            table.cell(0, j).text = column

            # Replace text boxes
            elif shape.has_text_frame:
                for text_info in text_boxes_to_replace:
                    if shape.name == text_info['name']:
                        text_frame = shape.text_frame
                        for paragraph in text_frame.paragraphs:
                            paragraph.text = text_info['new_text']

    # Save the updated presentation
    prs.save(output_pptx_path)

    # Convert the updated presentation to PDF using comtypes
    powerpoint = comtypes.client.CreateObject("PowerPoint.Application")
    powerpoint.Visible = 1
    presentation = powerpoint.Presentations.Open(output_pptx_path)
    presentation.SaveAs(output_pdf_path, 32)  # 32 is the formatType for PDF
    presentation.Close()
    powerpoint.Quit()

# Example usage:
data1 = {
    'Category': ['A', 'B', 'C', 'D'],
    'Values': [10, 20, 30, 40]
}
df1 = pd.DataFrame(data1)

data2 = {
    'Category': ['W', 'X', 'Y', 'Z'],
    'Values': [15, 25, 35, 45]
}
df2 = pd.DataFrame(data2)

images_to_replace = [
    {
        'name': 'ReplaceMe1',
        'dataframe': df1,
        'description': 'This is the new chart created from the first DataFrame.'
    },
    {
        'name': 'ReplaceMe2',
        'dataframe': df2,
        'description': 'This is the new chart created from the second DataFrame.'
    }
]

tables_to_replace = [
    {
        'name': 'TableReplaceMe1',
        'dataframe': df1
    },
    {
        'name': 'TableReplaceMe2',
        'dataframe': df2
    }
]

text_boxes_to_replace = [
    {
        'name': 'DateTextBox1',
        'new_text': '2024-07-27'
    },
    {
        'name': 'DateTextBox2',
        'new_text': '2024-07-27'
    }
]

# Paths
pptx_path = 'existing_presentation.pptx'
output_pptx_path = 'updated_presentation.pptx'
output_pdf_path = 'updated_presentation.pdf'

# Update the presentation and save as PDF
update_presentation(pptx_path, output_pptx_path, output_pdf_path, images_to_replace, tables_to_replace, text_boxes_to_replace)







##############

from pptx import Presentation
from pptx.util import Inches, Pt
import pandas as pd
import matplotlib.pyplot as plt
import io
from pptx2pdf import convert
import os

def update_presentation(pptx_path, output_pptx_path, output_pdf_path, images_to_replace, tables_to_replace, text_boxes_to_replace):
    # Load the existing presentation
    prs = Presentation(pptx_path)

    # Function to create a chart from a dataframe and return as an image stream
    def create_chart_image(dataframe):
        fig, ax = plt.subplots()
        ax.bar(dataframe['Category'], dataframe['Values'])
        ax.set_title("Sample Data Chart")

        # Save the plot to a BytesIO object
        img_stream = io.BytesIO()
        plt.savefig(img_stream, format='png')
        img_stream.seek(0)

        # Close the plot to free memory
        plt.close(fig)
        
        return img_stream

    # Iterate over slides and shapes to find and replace images, tables, and text boxes by their names
    for slide in prs.slides:
        for shape in slide.shapes:
            # Replace images
            if shape.shape_type == 13:  # 13 corresponds to picture shapes
                for image_info in images_to_replace:
                    if shape.name == image_info['name']:
                        # Get the position and size of the old image
                        left = shape.left
                        top = shape.top
                        width = shape.width
                        height = shape.height

                        # Remove the old picture
                        slide.shapes._spTree.remove(shape._element)

                        # Create the new chart image
                        chart_image_stream = create_chart_image(image_info['dataframe'])

                        # Add the new chart image with the same name
                        new_image = slide.shapes.add_picture(chart_image_stream, left, top, width, height)
                        new_image.name = image_info['name']

                        # Add a text box for the description
                        text_left = left
                        text_top = top + height + Inches(0.2)
                        text_width = width
                        text_height = Inches(1)

                        text_box = slide.shapes.add_textbox(text_left, text_top, text_width, text_height)
                        text_frame = text_box.text_frame
                        p = text_frame.add_paragraph()
                        p.text = image_info['description']
                        p.font.size = Pt(14)

            # Replace tables
            elif shape.shape_type == 19:  # 19 corresponds to table shapes
                for table_info in tables_to_replace:
                    if shape.name == table_info['name']:
                        table = shape.table
                        dataframe = table_info['dataframe']

                        # Clear the existing table contents
                        for row in table.rows:
                            for cell in row.cells:
                                cell.text = ''

                        # Fill the table with new data
                        for i, row in dataframe.iterrows():
                            for j, value in enumerate(row):
                                table.cell(i+1, j).text = str(value)  # +1 to skip header row

                        # Update the header row
                        for j, column in enumerate(dataframe.columns):
                            table.cell(0, j).text = column

            # Replace text boxes
            elif shape.has_text_frame:
                for text_info in text_boxes_to_replace:
                    if shape.name == text_info['name']:
                        text_frame = shape.text_frame
                        for paragraph in text_frame.paragraphs:
                            paragraph.text = text_info['new_text']

    # Save the updated presentation
    prs.save(output_pptx_path)

    # Convert the updated presentation to PDF
    convert(output_pptx_path, output_pdf_path)

# Example usage:
data1 = {
    'Category': ['A', 'B', 'C', 'D'],
    'Values': [10, 20, 30, 40]
}
df1 = pd.DataFrame(data1)

data2 = {
    'Category': ['W', 'X', 'Y', 'Z'],
    'Values': [15, 25, 35, 45]
}
df2 = pd.DataFrame(data2)

images_to_replace = [
    {
        'name': 'ReplaceMe1',
        'dataframe': df1,
        'description': 'This is the new chart created from the first DataFrame.'
    },
    {
        'name': 'ReplaceMe2',
        'dataframe': df2,
        'description': 'This is the new chart created from the second DataFrame.'
    }
]

tables_to_replace = [
    {
        'name': 'TableReplaceMe1',
        'dataframe': df1
    },
    {
        'name': 'TableReplaceMe2',
        'dataframe': df2
    }
]

text_boxes_to_replace = [
    {
        'name': 'DateTextBox1',
        'new_text': '2024-07-27'
    },
    {
        'name': 'DateTextBox2',
        'new_text': '2024-07-27'
    }
]

# Paths
pptx_path = 'existing_presentation.pptx'
output_pptx_path = 'updated_presentation.pptx'
output_pdf_path = 'updated_presentation.pdf'

# Update the presentation and save as PDF
update_presentation(pptx_path, output_pptx_path, output_pdf_path, images_to_replace, tables_to_replace, text_boxes_to_replace)


-/-/-/-/-/-/-/--





from pptx import Presentation
from pptx.util import Inches, Pt
import pandas as pd
import matplotlib.pyplot as plt
import io

# Sample dataframes
data1 = {
    'Category': ['A', 'B', 'C', 'D'],
    'Values': [10, 20, 30, 40]
}
df1 = pd.DataFrame(data1)

data2 = {
    'Category': ['W', 'X', 'Y', 'Z'],
    'Values': [15, 25, 35, 45]
}
df2 = pd.DataFrame(data2)

# Load the existing presentation
prs = Presentation('existing_presentation.pptx')

# Function to create a chart from a dataframe and return as an image stream
def create_chart_image(dataframe):
    fig, ax = plt.subplots()
    ax.bar(dataframe['Category'], dataframe['Values'])
    ax.set_title("Sample Data Chart")

    # Save the plot to a BytesIO object
    img_stream = io.BytesIO()
    plt.savefig(img_stream, format='png')
    img_stream.seek(0)

    # Close the plot to free memory
    plt.close(fig)
    
    return img_stream

# List of image names to replace and corresponding dataframes and descriptions
images_to_replace = [
    {
        'name': 'ReplaceMe1',
        'dataframe': df1,
        'description': 'This is the new chart created from the first DataFrame.'
    },
    {
        'name': 'ReplaceMe2',
        'dataframe': df2,
        'description': 'This is the new chart created from the second DataFrame.'
    }
]

# List of table names to replace and corresponding dataframes
tables_to_replace = [
    {
        'name': 'TableReplaceMe1',
        'dataframe': df1
    },
    {
        'name': 'TableReplaceMe2',
        'dataframe': df2
    }
]

# List of text box names to replace and corresponding new text
text_boxes_to_replace = [
    {
        'name': 'DateTextBox1',
        'new_text': '2024-07-27'
    },
    {
        'name': 'DateTextBox2',
        'new_text': '2024-07-27'
    }
]

# Iterate over slides and shapes to find and replace images, tables, and text boxes by their names
for slide in prs.slides:
    for shape in slide.shapes:
        # Replace images
        if shape.shape_type == 13:  # 13 corresponds to picture shapes
            for image_info in images_to_replace:
                if shape.name == image_info['name']:
                    # Get the position and size of the old image
                    left = shape.left
                    top = shape.top
                    width = shape.width
                    height = shape.height

                    # Remove the old picture
                    slide.shapes._spTree.remove(shape._element)

                    # Create the new chart image
                    chart_image_stream = create_chart_image(image_info['dataframe'])

                    # Add the new chart image with the same name
                    new_image = slide.shapes.add_picture(chart_image_stream, left, top, width, height)
                    new_image.name = image_info['name']

                    # Add a text box for the description
                    text_left = left
                    text_top = top + height + Inches(0.2)
                    text_width = width
                    text_height = Inches(1)

                    text_box = slide.shapes.add_textbox(text_left, text_top, text_width, text_height)
                    text_frame = text_box.text_frame
                    p = text_frame.add_paragraph()
                    p.text = image_info['description']
                    p.font.size = Pt(14)

        # Replace tables
        elif shape.shape_type == 19:  # 19 corresponds to table shapes
            for table_info in tables_to_replace:
                if shape.name == table_info['name']:
                    table = shape.table
                    dataframe = table_info['dataframe']

                    # Clear the existing table contents
                    for row in table.rows:
                        for cell in row.cells:
                            cell.text = ''

                    # Fill the table with new data
                    for i, row in dataframe.iterrows():
                        for j, value in enumerate(row):
                            table.cell(i+1, j).text = str(value)  # +1 to skip header row

                    # Update the header row
                    for j, column in enumerate(dataframe.columns):
                        table.cell(0, j).text = column

        # Replace text boxes
        elif shape.has_text_frame:
            for text_info in text_boxes_to_replace:
                if shape.name == text_info['name']:
                    text_frame = shape.text_frame
                    for paragraph in text_frame.paragraphs:
                        paragraph.text = text_info['new_text']

# Save the updated presentation
prs.save('updated_presentation.pptx')




--//:/:/:/;


from pptx import Presentation
from pptx.util import Inches, Pt
import pandas as pd
import matplotlib.pyplot as plt
import io

# Sample dataframes
data1 = {
    'Category': ['A', 'B', 'C', 'D'],
    'Values': [10, 20, 30, 40]
}
df1 = pd.DataFrame(data1)

data2 = {
    'Category': ['W', 'X', 'Y', 'Z'],
    'Values': [15, 25, 35, 45]
}
df2 = pd.DataFrame(data2)

# Load the existing presentation
prs = Presentation('existing_presentation.pptx')

# Function to create a chart from a dataframe and return as an image stream
def create_chart_image(dataframe):
    fig, ax = plt.subplots()
    ax.bar(dataframe['Category'], dataframe['Values'])
    ax.set_title("Sample Data Chart")

    # Save the plot to a BytesIO object
    img_stream = io.BytesIO()
    plt.savefig(img_stream, format='png')
    img_stream.seek(0)

    # Close the plot to free memory
    plt.close(fig)
    
    return img_stream

# List of image names to replace and corresponding dataframes and descriptions
images_to_replace = [
    {
        'name': 'ReplaceMe1',
        'dataframe': df1,
        'description': 'This is the new chart created from the first DataFrame.'
    },
    {
        'name': 'ReplaceMe2',
        'dataframe': df2,
        'description': 'This is the new chart created from the second DataFrame.'
    }
]

# List of table names to replace and corresponding dataframes
tables_to_replace = [
    {
        'name': 'TableReplaceMe1',
        'dataframe': df1
    },
    {
        'name': 'TableReplaceMe2',
        'dataframe': df2
    }
]

# Text to replace
old_text = 'CurrentDate'
new_text = '2024-07-27'

# Iterate over slides and shapes to find and replace images, tables, and text
for slide in prs.slides:
    for shape in slide.shapes:
        # Replace images
        if shape.shape_type == 13:  # 13 corresponds to picture shapes
            for image_info in images_to_replace:
                if shape.name == image_info['name']:
                    # Get the position and size of the old image
                    left = shape.left
                    top = shape.top
                    width = shape.width
                    height = shape.height

                    # Remove the old picture
                    slide.shapes._spTree.remove(shape._element)

                    # Create the new chart image
                    chart_image_stream = create_chart_image(image_info['dataframe'])

                    # Add the new chart image with the same name
                    new_image = slide.shapes.add_picture(chart_image_stream, left, top, width, height)
                    new_image.name = image_info['name']

                    # Add a text box for the description
                    text_left = left
                    text_top = top + height + Inches(0.2)
                    text_width = width
                    text_height = Inches(1)

                    text_box = slide.shapes.add_textbox(text_left, text_top, text_width, text_height)
                    text_frame = text_box.text_frame
                    p = text_frame.add_paragraph()
                    p.text = image_info['description']
                    p.font.size = Pt(14)

        # Replace tables
        elif shape.shape_type == 19:  # 19 corresponds to table shapes
            for table_info in tables_to_replace:
                if shape.name == table_info['name']:
                    table = shape.table
                    dataframe = table_info['dataframe']

                    # Clear the existing table contents
                    for row in table.rows:
                        for cell in row.cells:
                            cell.text = ''

                    # Fill the table with new data
                    for i, row in dataframe.iterrows():
                        for j, value in enumerate(row):
                            table.cell(i+1, j).text = str(value)  # +1 to skip header row

                    # Update the header row
                    for j, column in enumerate(dataframe.columns):
                        table.cell(0, j).text = column

        # Replace text
        elif shape.has_text_frame:
            text_frame = shape.text_frame
            for paragraph in text_frame.paragraphs:
                if old_text in paragraph.text:
                    paragraph.text = paragraph.text.replace(old_text, new_text)

# Save the updated presentation
prs.save('updated_presentation.pptx')








-----//-/---///------------

from pptx import Presentation
from pptx.util import Inches, Pt
import pandas as pd
import matplotlib.pyplot as plt
import io

# Sample dataframes
data1 = {
    'Category': ['A', 'B', 'C', 'D'],
    'Values': [10, 20, 30, 40]
}
df1 = pd.DataFrame(data1)

data2 = {
    'Category': ['W', 'X', 'Y', 'Z'],
    'Values': [15, 25, 35, 45]
}
df2 = pd.DataFrame(data2)

# Load the existing presentation
prs = Presentation('existing_presentation.pptx')

# Function to create a chart from a dataframe and return as an image stream
def create_chart_image(dataframe):
    fig, ax = plt.subplots()
    ax.bar(dataframe['Category'], dataframe['Values'])
    ax.set_title("Sample Data Chart")

    # Save the plot to a BytesIO object
    img_stream = io.BytesIO()
    plt.savefig(img_stream, format='png')
    img_stream.seek(0)

    # Close the plot to free memory
    plt.close(fig)
    
    return img_stream

# List of image names to replace and corresponding dataframes and descriptions
images_to_replace = [
    {
        'name': 'ReplaceMe1',
        'dataframe': df1,
        'description': 'This is the new chart created from the first DataFrame.'
    },
    {
        'name': 'ReplaceMe2',
        'dataframe': df2,
        'description': 'This is the new chart created from the second DataFrame.'
    }
]

# Iterate over slides and shapes to find and replace images by their names
for slide in prs.slides:
    for shape in slide.shapes:
        if shape.shape_type == 13:  # 13 corresponds to picture shapes
            for image_info in images_to_replace:
                if shape.name == image_info['name']:
                    # Get the position and size of the old image
                    left = shape.left
                    top = shape.top
                    width = shape.width
                    height = shape.height

                    # Remove the old picture
                    slide.shapes._spTree.remove(shape._element)

                    # Create the new chart image
                    chart_image_stream = create_chart_image(image_info['dataframe'])

                    # Add the new chart image with the same name
                    new_image = slide.shapes.add_picture(chart_image_stream, left, top, width, height)
                    new_image.name = image_info['name']

                    # Add a text box for the description
                    text_left = left
                    text_top = top + height + Inches(0.2)
                    text_width = width
                    text_height = Inches(1)

                    text_box = slide.shapes.add_textbox(text_left, text_top, text_width, text_height)
                    text_frame = text_box.text_frame
                    p = text_frame.add_paragraph()
                    p.text = image_info['description']
                    p.font.size = Pt(14)

# Save the updated presentation
prs.save('updated_presentation.pptx')








-------

from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.enum.shapes import MSO_SHAPE
import pandas as pd
import matplotlib.pyplot as plt
import io

# Sample dataframe
data = {
    'Category': ['A', 'B', 'C', 'D'],
    'Values': [10, 20, 30, 40]
}
df = pd.DataFrame(data)

# Load the existing presentation
prs = Presentation('existing_presentation.pptx')

# Function to create a chart from a dataframe and return as an image stream
def create_chart_image(dataframe):
    fig, ax = plt.subplots()
    ax.bar(dataframe['Category'], dataframe['Values'])
    ax.set_title("Sample Data Chart")

    # Save the plot to a BytesIO object
    img_stream = io.BytesIO()
    plt.savefig(img_stream, format='png')
    img_stream.seek(0)

    # Close the plot to free memory
    plt.close(fig)
    
    return img_stream

# Identify the specific image to replace (e.g., by its description or by iterating over shapes)
image_to_replace_description = "ReplaceMe"
new_image_description = "This is the new chart created from the DataFrame."

# Iterate over slides and shapes to find and replace the image
for slide in prs.slides:
    for shape in slide.shapes:
        if shape.shape_type == 13:  # 13 corresponds to picture shapes
            if shape.has_text_frame and shape.text_frame.text == image_to_replace_description:
                # Remove the old picture
                slide.shapes._spTree.remove(shape._element)

                # Create the new chart image
                chart_image_stream = create_chart_image(df)

                # Add the new chart image
                new_image = slide.shapes.add_picture(chart_image_stream, shape.left, shape.top, shape.width, shape.height)

                # Add a text box for the description
                left = new_image.left
                top = new_image.top + new_image.height + Inches(0.2)
                width = new_image.width
                height = Inches(1)

                text_box = slide.shapes.add_textbox(left, top, width, height)
                text_frame = text_box.text_frame
                p = text_frame.add_paragraph()
                p.text = new_image_description
                p.font.size = Pt(14)

                break

# Save the updated presentation
prs.save('updated_presentation.pptx')





-----

from pptx import Presentation
from pptx.util import Inches
from pptx.enum.shapes import MSO_SHAPE
import pandas as pd
import matplotlib.pyplot as plt
import io

# Sample dataframe
data = {
    'Category': ['A', 'B', 'C', 'D'],
    'Values': [10, 20, 30, 40]
}
df = pd.DataFrame(data)

# Load the existing presentation
prs = Presentation('existing_presentation.pptx')

# Function to add a table to a slide
def add_table_to_slide(slide, dataframe, title):
    rows, cols = dataframe.shape
    table = slide.shapes.add_table(rows + 1, cols, Inches(0.5), Inches(1.5), Inches(9.0), Inches(0.8 * (rows + 1))).table

    # Set column headings
    for i, column in enumerate(dataframe.columns):
        table.cell(0, i).text = column

    # Add the data
    for row in range(rows):
        for col in range(cols):
            table.cell(row + 1, col).text = str(dataframe.iat[row, col])

# Function to add a chart to a slide
def add_chart_to_slide(slide, dataframe, title):
    fig, ax = plt.subplots()
    ax.bar(dataframe['Category'], dataframe['Values'])
    ax.set_title(title)
    
    # Save the plot to a BytesIO object
    img_stream = io.BytesIO()
    plt.savefig(img_stream, format='png')
    img_stream.seek(0)

    # Add image to slide
    slide.shapes.add_picture(img_stream, Inches(0.5), Inches(1.5), Inches(9.0), Inches(4.5))

    # Close the plot to free memory
    plt.close(fig)

# Add a new slide for the table
slide_layout = prs.slide_layouts[5]  # Choosing a blank slide layout
slide = prs.slides.add_slide(slide_layout)
title = slide.shapes.title
title.text = "Data Table"
add_table_to_slide(slide, df, "Sample Data Table")

# Add a new slide for the chart
slide_layout = prs.slide_layouts[5]  # Choosing a blank slide layout
slide = prs.slides.add_slide(slide_layout)
title = slide.shapes.title
title.text = "Data Chart"
add_chart_to_slide(slide, df, "Sample Data Chart")

# Save the presentation
prs.save('updated_presentation.pptx')

----



import pandas as pd

# Sample dataframe
data = {
    'Category': ['A', 'A', 'B', 'B', 'C', 'C'],
    'Type': ['X', 'Y', 'X', 'Y', 'X', 'Y'],
    'Value': [10, 20, 15, 25, 10, 30]
}
df = pd.DataFrame(data)

# Groupby and pivot operations
grouped = df.groupby(['Category', 'Type']).sum().reset_index()
pivoted = df.pivot_table(index='Category', columns='Type', values='Value', aggfunc='sum').reset_index()

# Create Excel file with views
with pd.ExcelWriter('control_sheet.xlsx') as writer:
    df.to_excel(writer, sheet_name='Original Data', index=False)
    grouped.to_excel(writer, sheet_name='Grouped Data', index=False)
    pivoted.to_excel(writer, sheet_name='Pivoted Data', index=False)

----

from pptx import Presentation
from pptx.util import Inches
import pandas as pd

# Function to add a dataframe to a slide
def add_table_to_slide(slide, dataframe, title):
    rows, cols = dataframe.shape
    table = slide.shapes.add_table(rows + 1, cols, Inches(0.5), Inches(1.5), Inches(9.0), Inches(0.8 * (rows + 1))).table

    # Set title
    title_shape = slide.shapes.title
    title_shape.text = title

    # Set column headings
    for i, column in enumerate(dataframe.columns):
        table.cell(0, i).text = column

    # Add the data
    for row in range(rows):
        for col in range(cols):
            table.cell(row + 1, col).text = str(dataframe.iat[row, col])

# Create presentation object
prs = Presentation()

# Titles for slides
titles = ['Original Data', 'Grouped Data', 'Pivoted Data']
comments = ['This is the original dataset.', 'Data grouped by Category and Type.', 'Pivot table of the data.']

# Load data from the Excel file
with pd.ExcelFile('control_sheet.xlsx') as xls:
    for title, comment in zip(titles, comments):
        slide = prs.slides.add_slide(prs.slide_layouts[5])
        df = pd.read_excel(xls, sheet_name=title)
        add_table_to_slide(slide, df, title)
        
        # Add comments
        textbox = slide.shapes.add_textbox(Inches(0.5), Inches(5.5), Inches(9.0), Inches(1.0))
        text_frame = textbox.text_frame
        p = text_frame.add_paragraph()
        p.text = comment

# Save the presentation
prs.save('control_presentation.pptx')




---/

import openpyxl
import pandas as pd

# Function to unmerge cells and keep the value in the first cell
def unmerge_cells_to_dataframe(excel_file):
    # Load the Excel file
    wb = openpyxl.load_workbook(excel_file)
    ws = wb.active

    # Collect all merged cell ranges
    merged_ranges = list(ws.merged_cells.ranges)

    for merged_range in merged_ranges:
        merged_range_str = str(merged_range)
        top_left_cell = merged_range_str.split(":")[0]
        top_left_cell_value = ws[top_left_cell].value
        ws.unmerge_cells(merged_range_str)
        ws[top_left_cell].value = top_left_cell_value

    # Save the updated Excel file temporarily
    updated_excel_file = 'unmerged_excel_temp.xlsx'
    wb.save(updated_excel_file)

    # Load the unmerged Excel file into a Pandas DataFrame
    df = pd.read_excel(updated_excel_file)

    return df

# Specify the path to your Excel file
excel_file = 'path_to_your_excel_file.xlsx'

# Get the DataFrame after unmerging cells
df_unmerged = unmerge_cells_to_dataframe(excel_file)

print("DataFrame after unmerging cells:")
print(df_unmerged)

------





import openpyxl
import pandas as pd

# Load the Excel file
excel_file = 'path_to_your_excel_file.xlsx'
wb = openpyxl.load_workbook(excel_file)
ws = wb.active

# Function to unmerge cells and keep the value in the first cell
def unmerge_cells(ws):
    # Collect all merged cell ranges
    merged_ranges = list(ws.merged_cells.ranges)
    
    for merged_range in merged_ranges:
        merged_range_str = str(merged_range)
        top_left_cell = merged_range_str.split(":")[0]
        top_left_cell_value = ws[top_left_cell].value
        ws.unmerge_cells(merged_range_str)
        ws[top_left_cell].value = top_left_cell_value

# Unmerge cells in the active sheet
unmerge_cells(ws)

# Save the updated Excel file
updated_excel_file = 'unmerged_excel_file.xlsx'
wb.save(updated_excel_file)

# Load the unmerged Excel file into a Pandas DataFrame
df = pd.read_excel(updated_excel_file)

print("DataFrame after unmerging cells:")
print(df)

----



import openpyxl
import pandas as pd

# Load the Excel file
excel_file = 'path_to_your_excel_file.xlsx'
wb = openpyxl.load_workbook(excel_file)
ws = wb.active

# Function to unmerge cells and keep the value in the first cell
def unmerge_cells(ws):
    merged_cells = ws.merged_cells.ranges
    for merged_range in merged_cells:
        merged_range_str = str(merged_range)
        top_left_cell_value = ws[merged_range_str.split(":")[0]].value
        ws.unmerge_cells(merged_range_str)
        ws[merged_range_str.split(":")[0]] = top_left_cell_value

# Unmerge cells in the active sheet
unmerge_cells(ws)

# Save the updated Excel file
updated_excel_file = 'unmerged_excel_file.xlsx'
wb.save(updated_excel_file)

# Load the unmerged Excel file into a Pandas DataFrame
df = pd.read_excel(updated_excel_file)

print("DataFrame after unmerging cells:")
print(df)

------




import pandas as pd

# Sample DataFrame
data = {
    'Col1': [None, 'A', None, 'D'],
    'Col2': ['B', None, 'C', None],
    'Col3': [None, None, 'E', 'F'],
    'Col4': ['G', 'H', None, 'I']
}

df = pd.DataFrame(data)

print("Original DataFrame:")
print(df)

# Function to shift non-null values to the left
def shift_left(row):
    non_nulls = [x for x in row if pd.notnull(x)]
    nulls = [x for x in row if pd.isnull(x)]
    return non_nulls + nulls

# Apply the function to each row
df_shifted = df.apply(shift_left, axis=1, result_type='expand')

print("\nDataFrame after shifting values to the left:")
print(df_shifted)

-----


import fitz  # PyMuPDF
import csv

# Function to extract text from PDF and save to a CSV
def pdf_to_csv(pdf_path, csv_path):
    # Open the PDF
    pdf_document = fitz.open(pdf_path)
    
    # Create a list to hold the lines of text
    text_lines = []
    
    # Iterate through each page
    for page_num in range(pdf_document.page_count):
        page = pdf_document[page_num]
        text = page.get_text("text")
        # Split the text into lines and extend the list
        text_lines.extend(text.splitlines())
    
    # Remove blank lines
    text_lines = [line for line in text_lines if line.strip()]

    # Write the text lines to a CSV file
    with open(csv_path, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        for line in text_lines:
            writer.writerow([line])

# Example usage
pdf_path = 'path/to/your/file.pdf'
csv_path = 'path/to/your/output.csv'
pdf_to_csv(pdf_path, csv_path)




-----


import pandas as pd
import numpy as np

# Sample data
data = {
    'column1': ['text1', '1,500', '', '3,000', 'text2', ''],
    'column2': ['2', 'text3', '2,500.50', '', '5', ''],
    'description': ['', 'desc1', '', 'desc2', '', 'desc3']
}

# Creating DataFrame
df = pd.DataFrame(data)

def preprocess_value(value):
    # Check if the value is a string and contains a comma
    if isinstance(value, str) and ',' in value:
        # Remove commas and convert to float
        value = value.replace(',', '')
        try:
            value = float(value)
        except ValueError:
            pass  # Keep the original value if it cannot be converted to float
    return value

# Apply preprocessing to the columns
df['column1'] = df['column1'].apply(preprocess_value)
df['column2'] = df['column2'].apply(preprocess_value)

def concat_or_add(row):
    val1, val2 = row['column1'], row['column2']
    
    if (pd.isna(val1) or val1 == '') and (pd.isna(val2) or val2 == ''):
        return 'N.A.'
    
    if pd.isna(val1) or val1 == '':
        val1 = 0 if isinstance(val2, (int, float)) else ''
    if pd.isna(val2) or val2 == '':
        val2 = 0 if isinstance(val1, (int, float)) else ''
        
    if isinstance(val1, (int, float)) and isinstance(val2, (int, float)):
        return val1 + val2
    else:
        return str(val1) + str(val2)

df['column3'] = df.apply(concat_or_add, axis=1)

# Filter out rows where column3 contains only integer or float values and where the description is not blank
filtered_df = df[df['column3'].apply(lambda x: isinstance(x, (int, float))) & (df['description'].apply(pd.notna) & (df['description'] != ''))]

# Reset index for the filtered DataFrame
filtered_df.reset_index(drop=True, inplace=True)

print(filtered_df)




--------

import pandas as pd
import numpy as np

# Sample data
data = {
    'column1': ['text1', 1.5, '', 3, 'text2', ''],
    'column2': [2, 'text3', 2.5, '', 5, ''],
    'description': ['', 'desc1', '', 'desc2', '', 'desc3']
}

# Creating DataFrame
df = pd.DataFrame(data)

def concat_or_add(row):
    val1, val2 = row['column1'], row['column2']
    
    if (pd.isna(val1) or val1 == '') and (pd.isna(val2) or val2 == ''):
        return 'N.A.'
    
    if pd.isna(val1) or val1 == '':
        val1 = 0 if isinstance(val2, (int, float)) else ''
    if pd.isna(val2) or val2 == '':
        val2 = 0 if isinstance(val1, (int, float)) else ''
        
    if isinstance(val1, (int, float)) and isinstance(val2, (int, float)):
        return val1 + val2
    else:
        return str(val1) + str(val2)

df['column3'] = df.apply(concat_or_add, axis=1)

# Filter out rows where both columns contain float values and where the description is not blank
filtered_df = df[(df['column1'].apply(lambda x: isinstance(x, (int, float))) | df['column2'].apply(lambda x: isinstance(x, (int, float)))) & (df['description'] != '')]

# Reset index for the filtered DataFrame
filtered_df.reset_index(drop=True, inplace=True)

print(filtered_df)



----/

import pandas as pd
import numpy as np

# Sample data
data = {
    'column1': ['text1', 1.5, '', 3, 'text2'],
    'column2': [2, 'text3', 2.5, '', 5]
}

# Creating DataFrame
df = pd.DataFrame(data)

def concat_or_add(row):
    val1, val2 = row['column1'], row['column2']
    
    if pd.isna(val1) or val1 == '':
        val1 = 0 if isinstance(val2, (int, float)) else ''
    if pd.isna(val2) or val2 == '':
        val2 = 0 if isinstance(val1, (int, float)) else ''
        
    if isinstance(val1, (int, float)) and isinstance(val2, (int, float)):
        return val1 + val2
    else:
        return str(val1) + str(val2)

df['column3'] = df.apply(concat_or_add, axis=1)

print(df)





----------

import pandas as pd

def process_invoice_excel(input_excel_path, output_excel_path, column_names):
    # Read the Excel file starting from row 12
    df = pd.read_excel(input_excel_path, skiprows=11, header=None)
    
    # Set the column names explicitly
    df.columns = column_names

    # Remove completely blank rows
    df.dropna(how='all', inplace=True)

    # Remove rows with no relevant data
    df.dropna(subset=[column_names[0]], inplace=True)  # Assuming the first column is mandatory

    # Find the index of the "subtotal" row
    subtotal_index = df[df.apply(lambda row: row.astype(str).str.contains('subtotal', case=False).any(), axis=1)].index

    # If "subtotal" is found, keep rows only before "subtotal"
    if not subtotal_index.empty:
        df = df.loc[:subtotal_index[0] - 1]

    # Reset index for the cleaned DataFrame
    df.reset_index(drop=True, inplace=True)

    # Save the cleaned DataFrame to a new Excel file
    df.to_excel(output_excel_path, index=False)

# Example usage
input_excel_path = 'input_invoice.xlsx'
output_excel_path = 'cleaned_invoice_items.xlsx'
column_names = ["Description", "Quantity", "Price", "Total"]  # Adjust these as needed
process_invoice_excel(input_excel_path, output_excel_path, column_names)





----------

import pandas as pd

def process_invoice_excel(input_excel_path, output_excel_path):
    # Read the Excel file starting from row 12
    df = pd.read_excel(input_excel_path, skiprows=11)

    # Remove completely blank rows
    df.dropna(how='all', inplace=True)

    # Remove rows with no relevant data
    # Assuming 'Description' column is one of the mandatory fields for a valid row
    df.dropna(subset=['Description'], inplace=True)

    # Find the index of the "subtotal" row
    subtotal_index = df[df.apply(lambda row: row.astype(str).str.contains('subtotal', case=False).any(), axis=1)].index

    # If "subtotal" is found, keep rows only before "subtotal"
    if not subtotal_index.empty:
        df = df.loc[:subtotal_index[0] - 1]

    # Reset index for the cleaned DataFrame
    df.reset_index(drop=True, inplace=True)

    # Save the cleaned DataFrame to a new Excel file
    df.to_excel(output_excel_path, index=False)

# Example usage
input_excel_path = 'input_invoice.xlsx'
output_excel_path = 'cleaned_invoice_items.xlsx'
process_invoice_excel(input_excel_path, output_excel_path)










------------------

import pandas as pd

# Sample original data frame
data = {
    'Account': ['A001', 'A002', 'A003', 'A004', 'A005'],
    'Affiliate': ['Affiliate_1', 'Affiliate_None', 'Affiliate_2', 'Affiliate_None', 'Affiliate_3'],
    'Amount': [100, 200, 300, 400, 500]
}
df = pd.DataFrame(data)

# Reference table with account validity
reference_data = {
    'Account': ['A001', 'A002', 'A003', 'A004', 'A005'],
    'IsValid': ['y', 'y', 'n', 'y', 'n']
}
reference_df = pd.DataFrame(reference_data)

# Merge the original data frame with the reference table
merged_df = pd.merge(df, reference_df, on='Account')

# Filter the accounts where IsValid is 'y' and Affiliate is 'Affiliate_None'
invalid_affiliates = merged_df[(merged_df['IsValid'] == 'y') & (merged_df['Affiliate'] == 'Affiliate_None')]

# Get the list of such accounts
invalid_accounts = invalid_affiliates['Account'].tolist()

# Display the list of invalid accounts
print("List of accounts with invalid affiliates:", invalid_accounts)



---------

import os
import pandas as pd

# Example mapping dataframe
mapping_df = pd.DataFrame({
    'EntityId': [1, 2, 3, 4, 5, 'common'],
    'EntityCode': ['A', 'B', 'C', 'D', 'E', 'X']
})

# Path to the main folder containing subfolders with country dataframes
main_folder_path = 'path_to_main_folder'

# Loop through each subfolder
for country_folder in os.listdir(main_folder_path):
    country_folder_path = os.path.join(main_folder_path, country_folder)
    
    if os.path.isdir(country_folder_path):
        # Assuming each subfolder contains a CSV file with the country dataframe
        for file_name in os.listdir(country_folder_path):
            if file_name.endswith('.csv'):
                file_path = os.path.join(country_folder_path, file_name)
                
                # Load the country dataframe
                country_df = pd.read_csv(file_path)
                
                # Filter the mapping dataframe based on EntityId in country dataframe
                entity_ids_in_country = country_df['EntityId'].unique()
                filtered_mapping_df = mapping_df[mapping_df['EntityId'].isin(entity_ids_in_country) | (mapping_df['EntityId'] == 'common')]
                
                # Process the filtered mapping dataframe as needed
                print(f"Filtered mapping dataframe for {country_folder}:")
                print(filtered_mapping_df)

                # If you need to save or further process the filtered_mapping_df, you can do so here

-----------


import pandas as pd
import numpy as np

# Example dataframe
data = {'column': [np.nan, 'abc', np.nan, np.nan, 'abc']}
df = pd.DataFrame(data)

# Identify the single non-null value in the column
unique_values = df['column'].dropna().unique()

# Create the control DataFrame without NULL values
control_df = df.dropna().copy()

# Determine the message for control DataFrame
if len(unique_values) == 1:
    control_df['status'] = 'Unique value found'
    single_value = unique_values[0]
    # Fill NaN values with the single value in the original DataFrame
    df['column'].fillna(single_value, inplace=True)
else:
    control_df['status'] = 'More than one unique non-null value or none at all'

print("Original DataFrame after filling NaNs:")
print(df)
print("\nControl DataFrame:")
print(control_df)

---/--




import pandas as pd
from pandas import ExcelWriter

# Sample DataFrames
main_df = pd.DataFrame({'EntityId1_main': [1, 2, 3, 4, 5], 'EntityId2_main': [10, 20, 30, 40, 50], 'Value': [10, 20, 30, 40, 50]})
df1 = pd.DataFrame({'EntityId1': [1, 2, 3], 'MappedValue1': [100, 200, 300]})
df2 = pd.DataFrame({'Key1': [2, 3, 4], 'Key2': [20, 30, 40], 'MappedValue2': [150, 250, 350]})
df3 = pd.DataFrame({'Id': [1, 3, 5], 'MappedValue3': [110, 210, 310]})
df4 = pd.DataFrame({'Code': [1, 2, 4], 'MappedValue4': [120, 220, 320]})
df5 = pd.DataFrame({'ID': [2, 3, 5], 'MappedValue5': [130, 230, 330]})

mapping_dfs = [
    ('df1', df1, {'main': ['EntityId1_main'], 'map': ['EntityId1']}),
    ('df2', df2, {'main': ['EntityId1_main', 'EntityId2_main'], 'map': ['Key1', 'Key2']}),
    ('df3', df3, {'main': ['EntityId1_main'], 'map': ['Id']}),
    ('df4', df4, {'main': ['EntityId1_main'], 'map': ['Code']}),
    ('df5', df5, {'main': ['EntityId1_main'], 'map': ['ID']})
]

# Create a list to store the unmatched values
unmatched_values_list = []

# Merge main_df with each mapping DataFrame and track unmatched values
for name, mapping_df, keys in mapping_dfs:
    main_keys = keys['main']
    map_keys = keys['map']
    merged_df = main_df.merge(mapping_df, how='left', left_on=main_keys, right_on=map_keys, indicator=True)
    # Identify the rows in main_df that don't have matching rows in the mapping DataFrame
    unmatched = merged_df[merged_df['_merge'] == 'left_only'][main_keys]
    for value in unmatched.itertuples(index=False, name=None):
        unmatched_values_list.append([name, ', '.join(main_keys), ', '.join(map(str, value))])

# Create a DataFrame from the unmatched values list
unmatched_values_df = pd.DataFrame(unmatched_values_list, columns=['DataFrame', 'Key Column', 'Missing Value'])

# Create a summary count table
summary_counts = unmatched_values_df.groupby(['DataFrame', 'Key Column']).size().reset_index(name='Unmatched Count')

# Create a new Excel writer object
with ExcelWriter('control_sheet.xlsx') as writer:
    # Write the unmatched values to a single worksheet
    unmatched_values_df.to_excel(writer, sheet_name='Unmatched Values', index=False)
    
    # Write the summary count table to another worksheet
    summary_counts.to_excel(writer, sheet_name='Summary', index=False)

print("Control sheet with unmatched values and summary count table has been written to 'control_sheet.xlsx'.")





import pandas as pd
from pandas import ExcelWriter

# Sample DataFrames
main_df = pd.DataFrame({'EntityId1_main': [1, 2, 3, 4, 5], 'EntityId2_main': [10, 20, 30, 40, 50], 'Value': [10, 20, 30, 40, 50]})
df1 = pd.DataFrame({'EntityId1': [1, 2, 3], 'MappedValue1': [100, 200, 300]})
df2 = pd.DataFrame({'Key1': [2, 3, 4], 'Key2': [20, 30, 40], 'MappedValue2': [150, 250, 350]})
df3 = pd.DataFrame({'Id': [1, 3, 5], 'MappedValue3': [110, 210, 310]})
df4 = pd.DataFrame({'Code': [1, 2, 4], 'MappedValue4': [120, 220, 320]})
df5 = pd.DataFrame({'ID': [2, 3, 5], 'MappedValue5': [130, 230, 330]})

mapping_dfs = [
    ('df1', df1, {'main': ['EntityId1_main'], 'map': ['EntityId1']}),
    ('df2', df2, {'main': ['EntityId1_main', 'EntityId2_main'], 'map': ['Key1', 'Key2']}),
    ('df3', df3, {'main': ['EntityId1_main'], 'map': ['Id']}),
    ('df4', df4, {'main': ['EntityId1_main'], 'map': ['Code']}),
    ('df5', df5, {'main': ['EntityId1_main'], 'map': ['ID']})
]

# Create a list to store the unmatched values
unmatched_values_list = []

# Merge main_df with each mapping DataFrame and track unmatched values
for name, mapping_df, keys in mapping_dfs:
    main_keys = keys['main']
    map_keys = keys['map']
    merged_df = main_df.merge(mapping_df, how='left', left_on=main_keys, right_on=map_keys, indicator=True)
    # Identify the rows in main_df that don't have matching rows in the mapping DataFrame
    unmatched = merged_df[merged_df['_merge'] == 'left_only'][main_keys]
    for value in unmatched.itertuples(index=False):
        unmatched_values_list.append([name, ', '.join(main_keys), value])

# Create a DataFrame from the unmatched values list
unmatched_values_df = pd.DataFrame(unmatched_values_list, columns=['DataFrame', 'Key Column', 'Missing Value'])

# Create a summary count table
summary_counts = unmatched_values_df.groupby(['DataFrame', 'Key Column']).size().reset_index(name='Unmatched Count')

# Create a new Excel writer object
with ExcelWriter('control_sheet.xlsx') as writer:
    # Write the unmatched values to a single worksheet
    unmatched_values_df.to_excel(writer, sheet_name='Unmatched Values', index=False)
    
    # Write the summary count table to another worksheet
    summary_counts.to_excel(writer, sheet_name='Summary', index=False)

print("Control sheet with unmatched values and summary count table has been written to 'control_sheet.xlsx'.")

----------




import pandas as pd
from pandas import ExcelWriter

# Sample DataFrames
main_df = pd.DataFrame({'EntityId1': [1, 2, 3, 4, 5], 'EntityId2': [10, 20, 30, 40, 50], 'Value': [10, 20, 30, 40, 50]})
df1 = pd.DataFrame({'EntityId1': [1, 2, 3], 'MappedValue1': [100, 200, 300]})
df2 = pd.DataFrame({'Key1': [2, 3, 4], 'Key2': [20, 30, 40], 'MappedValue2': [150, 250, 350]})
df3 = pd.DataFrame({'Id': [1, 3, 5], 'MappedValue3': [110, 210, 310]})
df4 = pd.DataFrame({'Code': [1, 2, 4], 'Details': [10, 20, 30, 40, 50]})
df5 = pd.DataFrame({'ID': [2, 3, 5], 'Description': [1, 2, 3, 4, 5]})

mapping_dfs = [
    ('df1', df1, ['EntityId1']),
    ('df2', df2, ['Key1', 'Key2']),
    ('df3', df3, ['Id']),
    ('df4', df4, ['Code']),
    ('df5', df5, ['ID'])
]

# Create a list to store the unmatched values
unmatched_values_list = []

# Merge main_df with each mapping DataFrame and track unmatched values
for name, mapping_df, keys in mapping_dfs:
    merged_df = main_df.merge(mapping_df, how='left', left_on=keys, right_on=keys)
    # Identify the rows in main_df that don't have matching rows in the mapping DataFrame
    unmatched = merged_df[merged_df[keys[0]].isna()][keys]
    for value in unmatched.itertuples(index=False):
        unmatched_values_list.append([name, ', '.join(keys), tuple(value)])

# Create a DataFrame from the unmatched values list
unmatched_values_df = pd.DataFrame(unmatched_values_list, columns=['DataFrame', 'Key Column', 'Missing Value'])

# Create a summary count table
summary_counts = unmatched_values_df.groupby(['DataFrame', 'Key Column']).size().reset_index(name='Unmatched Count')

# Create a new Excel writer object
with ExcelWriter('control_sheet.xlsx') as writer:
    # Write the unmatched values to a single worksheet
    unmatched_values_df.to_excel(writer, sheet_name='Unmatched Values', index=False)
    
    # Write the summary count table to another worksheet
    summary_counts.to_excel(writer, sheet_name='Summary', index=False)

print("Control sheet with unmatched values and summary count table has been written to 'control_sheet.xlsx'.")

----//////



import pandas as pd
from pandas import ExcelWriter

# Sample DataFrames
main_df = pd.DataFrame({'EntityId': [1, 2, 3, 4, 5], 'Value': [10, 20, 30, 40, 50]})
df1 = pd.DataFrame({'EntityId': [1, 2, 3], 'MappedValue1': [100, 200, 300]})
df2 = pd.DataFrame({'Key': [2, 3, 4], 'MappedValue2': [150, 250, 350]})
df3 = pd.DataFrame({'Id': [1, 3, 5], 'MappedValue3': [110, 210, 310]})
df4 = pd.DataFrame({'Code': [1, 2, 4], 'MappedValue4': [120, 220, 320]})
df5 = pd.DataFrame({'ID': [2, 3, 5], 'MappedValue5': [130, 230, 330]})

mapping_dfs = [
    ('df1', df1, 'EntityId'),
    ('df2', df2, 'Key'),
    ('df3', df3, 'Id'),
    ('df4', df4, 'Code'),
    ('df5', df5, 'ID')
]

# Create a list to store the unmatched values
unmatched_values_list = []

# Merge main_df with each mapping DataFrame and track unmatched values
for name, mapping_df, key in mapping_dfs:
    merged_df = main_df.merge(mapping_df, how='left', left_on='EntityId', right_on=key)
    unmatched = merged_df[merged_df[key].isna()]['EntityId']
    for value in unmatched:
        unmatched_values_list.append([name, key, value])

# Create a DataFrame from the unmatched values list
unmatched_values_df = pd.DataFrame(unmatched_values_list, columns=['DataFrame', 'Key Column', 'Missing Value'])

# Create a summary count table
summary_counts = unmatched_values_df.groupby(['DataFrame', 'Key Column']).size().reset_index(name='Unmatched Count')

# Create a new Excel writer object
with ExcelWriter('control_sheet.xlsx') as writer:
    # Write the unmatched values to a single worksheet
    unmatched_values_df.to_excel(writer, sheet_name='Unmatched Values', index=False)
    
    # Write the summary count table to another worksheet
    summary_counts.to_excel(writer, sheet_name='Summary', index=False)

print("Control sheet with unmatched values and summary count table has been written to 'control_sheet.xlsx'.")

-------------




import pandas as pd
from pandas import ExcelWriter

# Sample DataFrames
main_df = pd.DataFrame({'EntityId': [1, 2, 3, 4, 5], 'Value': [10, 20, 30, 40, 50]})
df1 = pd.DataFrame({'EntityId': [1, 2, 3], 'MappedValue1': [100, 200, 300]})
df2 = pd.DataFrame({'Key': [2, 3, 4], 'MappedValue2': [150, 250, 350]})
df3 = pd.DataFrame({'Id': [1, 3, 5], 'MappedValue3': [110, 210, 310]})
df4 = pd.DataFrame({'Code': [1, 2, 4], 'MappedValue4': [120, 220, 320]})
df5 = pd.DataFrame({'ID': [2, 3, 5], 'MappedValue5': [130, 230, 330]})

mapping_dfs = [
    ('df1', df1, 'EntityId'),
    ('df2', df2, 'Key'),
    ('df3', df3, 'Id'),
    ('df4', df4, 'Code'),
    ('df5', df5, 'ID')
]

# Create a summary count table
summary_counts = []

# Create a dictionary to store unmatched values
unmatched_values = {name: [] for name, _, _ in mapping_dfs}

# Merge main_df with each mapping DataFrame and track unmatched values
for name, mapping_df, key in mapping_dfs:
    merged_df = main_df.merge(mapping_df, how='left', left_on='EntityId', right_on=key)
    unmatched = merged_df[merged_df[key].isna()]['EntityId']
    unmatched_values[name].extend(unmatched.tolist())
    summary_counts.append([name, len(unmatched)])

# Create a summary DataFrame
summary_df = pd.DataFrame(summary_counts, columns=['DataFrame', 'Unmatched Count'])

# Create a new Excel writer object
with ExcelWriter('control_sheet.xlsx') as writer:
    # Write the summary count table
    summary_df.to_excel(writer, sheet_name='Summary', index=False)
    
    # Write the unmatched values to separate worksheets
    for name, values in unmatched_values.items():
        if values:
            unmatched_df = pd.DataFrame(values, columns=['Unmatched EntityId'])
            unmatched_df.to_excel(writer, sheet_name=f'Unmatched_{name}', index=False)

print("Control sheet with unmatched values and summary count table has been written to 'control_sheet.xlsx'.")




-----------


import pandas as pd
from pandas import ExcelWriter

# Sample DataFrames and their names and key columns
df1 = pd.DataFrame({'EntityId': [1, 2, 3, 4, 1], 'Value': [10, 20, 30, 40, 50]})
df2 = pd.DataFrame({'Key1': [5, 6, 7, 8, 5], 'Key2': [1, 2, 3, 4, 1], 'Data': [100, 200, 300, 400, 500]})
df3 = pd.DataFrame({'Id': [9, 10, 11, 12, 12], 'Info': [1000, 2000, 3000, 4000, 5000]})
df4 = pd.DataFrame({'Code': [13, 14, 15, 16, 13], 'Details': [10, 20, 30, 40, 50]})
df5 = pd.DataFrame({'ID': [17, 18, 19, 20, 20], 'Description': [1, 2, 3, 4, 5]})

dataframes = [
    ('df1', df1, ['EntityId']),
    ('df2', df2, ['Key1', 'Key2']),
    ('df3', df3, ['Id']),
    ('df4', df4, ['Code']),
    ('df5', df5, ['ID'])
]

# Consolidated results DataFrame
consolidated_results = []

# Create a new Excel writer object
with ExcelWriter('duplicates_only.xlsx') as writer:
    for name, df, keys in dataframes:
        # Find duplicate rows
        duplicates = df[df.duplicated(subset=keys, keep=False)]
        
        # Count the number of unique items where the total count is greater than 1
        unique_counts = df.groupby(keys).size()
        duplicate_count = unique_counts[unique_counts > 1].count()
        
        # Append the results to the consolidated list
        consolidated_results.append([name, ', '.join(keys), duplicate_count])
        
        # Write the duplicates to the Excel sheet if any
        if not duplicates.empty:
            duplicates.to_excel(writer, sheet_name=f'duplicates_{name}', index=False)

    # Create a DataFrame from the consolidated results
    consolidated_df = pd.DataFrame(consolidated_results, columns=['DataFrame', 'Key Columns', 'Duplicate Count'])
    
    # Write the consolidated results to the Excel sheet
    consolidated_df.to_excel(writer, sheet_name='Consolidated Results', index=False)

print("Duplicates and consolidated results have been written to 'duplicates_only.xlsx'.")

-----------///////------





import pandas as pd
from pandas import ExcelWriter

# Sample DataFrames and their key columns
df1 = pd.DataFrame({'EntityId': [1, 2, 3, 4, 1], 'Value': [10, 20, 30, 40, 50]})
df2 = pd.DataFrame({'Key': [5, 6, 7, 8, 5], 'Data': [100, 200, 300, 400, 500]})
df3 = pd.DataFrame({'Id': [9, 10, 11, 12, 12], 'Info': [1000, 2000, 3000, 4000, 5000]})
df4 = pd.DataFrame({'Code': [13, 14, 15, 16, 13], 'Details': [10, 20, 30, 40, 50]})
df5 = pd.DataFrame({'ID': [17, 18, 19, 20, 20], 'Description': [1, 2, 3, 4, 5]})

dataframes = [
    (df1, 'EntityId'),
    (df2, 'Key'),
    (df3, 'Id'),
    (df4, 'Code'),
    (df5, 'ID')
]

# Create a new Excel writer object
with ExcelWriter('data_with_duplicates.xlsx') as writer:
    for idx, (df, key) in enumerate(dataframes, start=1):
        # Check for duplicates
        duplicates = df[df.duplicated(key, keep=False)]
        
        # Write the original DataFrame to the Excel sheet
        df.to_excel(writer, sheet_name=f'DataFrame{idx}', index=False)
        
        # Write the duplicates to the Excel sheet if any
        if not duplicates.empty:
            duplicates.to_excel(writer, sheet_name=f'Duplicates{idx}', index=False)

print("DataFrames and duplicates have been written to 'data_with_duplicates.xlsx'.")








import pandas as pd

# Sample DataFrame with string and float columns
data = {
    'col1': [1, 2, 3],
    'col2': [4.5, 5.5, 6.5],  # Column to keep all decimals
    'col3': [7, 8, 9],
    'col4': [10, 11, 12],
    'col5': ['A', 'B', 'C'],  # String column
    'col6': [16, 17, 18],
    'col7': ['X', 'Y', 'Z'],  # String column
    'col8': [22, 23, 24],
    'col9': [25, 26, 27],
    'col10': [28.5, 29.5, 30.5]  # Column to round to zero decimals
}

df = pd.DataFrame(data)

# File path
file_path = 'output.txt'

# Header string
header = "My data is here:"

# Specify the column names
float_col_to_round = 'col10'
float_col_keep_decimals = 'col2'

# Write to file with header
with open(file_path, 'w') as file:
    file.write(f'{header}\n')
    for index, row in df.iterrows():
        formatted_values = []
        for col in df.columns:
            value = row[col]
            if col == float_col_to_round:
                formatted_values.append(f'{value:.0f}')  # Round to zero decimals
            else:
                formatted_values.append(f'{value}')
        line = ';'.join(formatted_values)
        file.write(f'{line}\n')

# Display the content of the text file for verification
with open(file_path, 'r') as file:
    print(file.read())





import pandas as pd

# Example DataFrame
df = pd.DataFrame({
    'column2': ['A', 'B', 'C', 'D', 'A', 'F']
})

# Example mapping DataFrame
mapping_df = pd.DataFrame({
    'column2': ['B', 'C', 'D'],
    'column3': ['MappedValue1', 'MappedValue2', 'MappedValue3']
})

# Define a function to apply the logic
def populate_column1(row, mapping_dict):
    if row['column2'] == 'A':
        return 'b'
    elif row['column2'] in mapping_dict:
        return mapping_dict[row['column2']]
    else:
        return 'e'

# Create a dictionary for faster lookup from the mapping DataFrame
mapping_dict = mapping_df.set_index('column2')['column3'].to_dict()

# Apply the function to populate 'column1'
df['column1'] = df.apply(populate_column1, axis=1, mapping_dict=mapping_dict)

print(df)








= let
    Value = [Value],
    Currency = [Currency],
    RangeStart = Number.RoundDown(Value / 50000) * 50000,
    RangeEnd = RangeStart + 49999,
    RangeText = if Value < 5000 then Currency & " less than " & Currency & " 5000" else Currency & " " & Text.From(RangeStart + 1) & " to " & Currency & " " & Text.From(RangeEnd)
in
    RangeText



import pandas as pd

# Sample data for the DataFrame
data = {
    'Categories': ['A', 'B', 'C', 'D'],
    'Values': [10, 20, 30, 40]
}

df = pd.DataFrame(data)

# Create a Pandas Excel writer using XlsxWriter as the engine
with pd.ExcelWriter('data_with_chart.xlsx', engine='xlsxwriter') as writer:
    # Write your DataFrame to an Excel file on Sheet1
    df.to_excel(writer, sheet_name='Sheet1', index=False)

    # Access the XlsxWriter workbook and worksheet objects from the dataframe
    workbook = writer.book
    worksheet = writer.sheets['Sheet1']
    
    # Create a bar chart object
    chart = workbook.add_chart({'type': 'bar'})

    # Configure the series of the chart from the DataFrame data. 
    # Here we need to adjust the cell range based on the DataFrame's size
    chart.add_series({
        'categories': '=Sheet1!$A$2:$A$5',
        'values':     '=Sheet1!$B$2:$B$5',
    })

    # Optionally, add chart title, axis titles, etc.
    chart.set_title({'name': 'Values by Category'})
    chart.set_x_axis({'name': 'Category'})
    chart.set_y_axis({'name': 'Value'})

    # Insert the chart into the worksheet with an offset
    worksheet.insert_chart('D2', chart)

# Note: The Excel file 'data_with_chart.xlsx' is saved in your current directory.